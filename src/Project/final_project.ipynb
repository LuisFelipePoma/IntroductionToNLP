{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmgYAll-rfQG"
      },
      "source": [
        "# Reviews de Amazon basado en NLP - Proyecto Final\n",
        "#### **Objetivo: Predicción de ratings basado en reviews de videojuegos vendidos Amazon**\n",
        "\n",
        "En la plataforma de Amazon, los usuarios pueden ingresar sus comentarios y ratings con respecto a un producto adquirido. Sin embargo, muchos usuarios solo colocan un review, lo cual dificulta a Amazon mantener un registro de calificaciones por cada uno de sus registros. Por ello, este modelo busca predecir la clasificación dada a raíz de un comentario mediante un sistema de rating del 1 al 5.\n",
        "\n",
        "- Input: El videojuego es increíble. Garantiza muchas horas de diversión!\n",
        "- Output: 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDu4x0GVRqE"
      },
      "source": [
        "# Importar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urxfhlehVNVI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "## Librerias para graficación\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IwbdFalVU_W"
      },
      "source": [
        "# Cargar el Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJIEglbO-00M"
      },
      "source": [
        "## Lectura del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJKEU4Oz-0jO",
        "outputId": "65382455-a361-48e6-ba37-b6482cacaef8"
      },
      "outputs": [],
      "source": [
        "!wget \"https://huggingface.co/api/datasets/amazon_us_reviews/parquet/Video_Games_v1_00/train/0.parquet\"\n",
        "!wget \"https://huggingface.co/api/datasets/amazon_us_reviews/parquet/Video_Games_v1_00/train/1.parquet\"\n",
        "!wget \"https://huggingface.co/api/datasets/amazon_us_reviews/parquet/Video_Games_v1_00/train/2.parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKQ1-fU8VUhJ"
      },
      "outputs": [],
      "source": [
        "# Se leen todos los datasets y se unen en uno solo\n",
        "df0 = pd.read_parquet(\"0.parquet\")\n",
        "df1 = pd.read_parquet(\"1.parquet\")\n",
        "df2 = pd.read_parquet(\"2.parquet\")\n",
        "df = pd.concat([df0, df1, df2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQlPBS21VUmU",
        "outputId": "96dd1350-8c7e-4286-bb8a-46b5df9bc3d8"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "Wz56wOo52_ev",
        "outputId": "ad432b45-8b0f-4b1e-ce51-2388a1472f35"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "OFNAjYOnHZBR",
        "outputId": "27180998-b7f9-4629-a857-8ce6db1a5d39"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x='star_rating', kind='count', color='r', data=df)\n",
        "plt.title('Distribución de Rating')\n",
        "plt.xlabel('star_rating')\n",
        "plt.ylabel('Conteo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LpC0G1SAJM5"
      },
      "source": [
        "## Sample del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e--1CnbwCMDm"
      },
      "outputs": [],
      "source": [
        "# Funcion para balancear el dataset\n",
        "def balancear_dataset_por_rating(data_frame):\n",
        "    # Obtenemos el recuento de cada valor de \"rating\"\n",
        "    conteo_ratings = data_frame['star_rating'].value_counts()\n",
        "\n",
        "    # Obtenemos el mínimo de ocurrencias de \"rating\" que queremos mantener\n",
        "    min_ocurrencias = min(conteo_ratings)\n",
        "\n",
        "    # Filtramos las filas que tienen \"rating\" mayor o igual al mínimo especificado\n",
        "    data_frame_balanceado = data_frame.groupby('star_rating').apply(lambda x: x.sample(min_ocurrencias, random_state=42))\n",
        "\n",
        "    # Restablecemos el índice del DataFrame resultante y eliminamos el índice antiguo\n",
        "    data_frame_balanceado.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return data_frame_balanceado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQWS0JY0CTjQ"
      },
      "outputs": [],
      "source": [
        "df_train = balancear_dataset_por_rating(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O35YclkS35zp",
        "outputId": "a746206c-4b79-444b-de7e-b354b449df87"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaA4_Xu1Aig1"
      },
      "outputs": [],
      "source": [
        "# Creamos una nueva columna con el titulo y la review del juego\n",
        "df_train['text'] = df_train['review_headline'] + ' ' + df_train['review_body']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m4yzKomHRfzV",
        "outputId": "0c9e7775-1f34-4f82-fa6e-cbd2152ab4a3"
      },
      "outputs": [],
      "source": [
        "# Se obtiene una muestra del dataset\n",
        "df_train = df_train.sample(200000,random_state=42)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_train = df_train[[\"text\", \"star_rating\"]]\n",
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "FguYh5mnr06C",
        "outputId": "82d3821e-4990-4837-fdf4-22a6e811889c"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x='star_rating', kind='count', color='r', data=df_train)\n",
        "plt.title('Distribución de Rating')\n",
        "plt.xlabel('star_rating')\n",
        "plt.ylabel('Conteo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vghh3UxRAmky"
      },
      "source": [
        "# Modelamiento por Arquitecturas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhfVuGMGu3Co",
        "outputId": "fc46ef05-4de1-4185-e5ad-dec75fb841a6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stemmer = nltk.stem.SnowballStemmer('english')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRQHt1gCr8Aj"
      },
      "source": [
        "## BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qpHwvPYAqYF"
      },
      "outputs": [],
      "source": [
        "def processing_text(texto):\n",
        "    # Paso 1: Remover con un expresión regular carateres especiales (no palabras).\n",
        "    processed_feature = re.sub(r'\\W', ' ', str(texto))\n",
        "    # Paso 2: Remover ocurrencias de caracteres individuales\n",
        "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "    # Paso 3: Remover números (Ocurrencias muy esporádicas en nuestro dataset)\n",
        "    processed_feature = re.sub(r'[0-9]+', ' ', processed_feature)\n",
        "    # Paso 4: Simplificar espacios concecutivos a un único espacio entre palabras\n",
        "    processed_feature = re.sub(' +', ' ', processed_feature)\n",
        "    # Paso 5: Pasar todo el texto a minúsculas\n",
        "    processed_feature = processed_feature.lower()\n",
        "    # Paso 6: Aplicar stemming. Es una forma de enviar las palabras a una raiz común simplificando de esta manera el vocabulario.\n",
        "    #         por ejemplo las palabras (absurdo, absurdos) que estan en el review 2895 seran llevados a la raiz común \"absurd\"\n",
        "    #         y de esta forma se evita tener dos palabras diferentes con el mismo significado en nuestro vocabulario.\n",
        "    processed_feature = \" \".join([stemmer.stem(i) for i in processed_feature.split()])\n",
        "\n",
        "    return processed_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdZAH3K0As6H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# texto_para_procesar y labels respectivamente\n",
        "texto_para_procesar = df_train['text'].values\n",
        "labels = df_train['star_rating'].values\n",
        "\n",
        "# El texto ya procesado de cada ejemplo en nuestro dataset lo almacenaremos en la variable \"texto_procesado\"\n",
        "texto_procesado = []\n",
        "for sentence in range(0, len(texto_para_procesar)):\n",
        "    procesado = processing_text(texto_para_procesar[sentence])\n",
        "    texto_procesado.append(procesado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0HEHwpAnGP"
      },
      "source": [
        "## Naives Bayes (MultinomialNB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ1zYqZcAo94"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO2HOCvvIFHv"
      },
      "outputs": [],
      "source": [
        "def create_model_naives(texto_features):\n",
        "    # Partición del dataset: Seleccionar 80% para entrenamiento, 20% pruebas.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(texto_features, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Modelo: Naive Bayes\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Reporte de clasificación\n",
        "    predictions = model.predict(X_test)\n",
        "    print(classification_report(y_test, predictions, digits=4))\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, predictions,labels=model.classes_)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "    disp.plot()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncHBHKciAuZN"
      },
      "source": [
        "### Representacion 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqwWL_kiDThh",
        "outputId": "65226896-2e31-4ef5-e5f4-987a43909301"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=1000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_naives(texto_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh6ABfJuAvo-"
      },
      "source": [
        "### Representacion 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wWt3CLStQE_",
        "outputId": "36faba2c-a230-4057-bf40-747ac6efe669"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=2500, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_naives(texto_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzUzefj6AyNZ"
      },
      "source": [
        "### Representacion 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "RYr4jkTdtRID",
        "outputId": "1b680518-d8ed-4d13-e166-4228afa01cc4"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=3000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_naives(texto_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd_IP0obA9uR"
      },
      "source": [
        "## Logistic Regresion (SDGClassfier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPelrIJ_A_Kb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrIhvy8rzMio"
      },
      "outputs": [],
      "source": [
        "def create_model_sdg(texto_features, eta = 0.1):\n",
        "    # Partición del dataset: Seleccionar 80% para entrenamiento, 20% pruebas.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        texto_features, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Modelo: SGDClassifier\n",
        "    model = SGDClassifier(loss='log_loss', learning_rate='constant', eta0=eta)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Reporte de clasificación\n",
        "    predictions = model.predict(X_test)\n",
        "    print(classification_report(y_test, predictions, digits=4))\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, predictions, labels=model.classes_)\n",
        "    disp = ConfusionMatrixDisplay(\n",
        "        confusion_matrix=cm, display_labels=model.classes_)\n",
        "    disp.plot()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3BBGWkZA-R6"
      },
      "source": [
        "### Representacion 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "FBh4oWNLzQzX",
        "outputId": "785f39cb-ef71-4762-c967-e89d6cc1ca8c"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=3000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_sdg(texto_features,eta=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm24VD7zBA88"
      },
      "source": [
        "### Representacion 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "36qwiwUDzSTY",
        "outputId": "deccc38f-f4f4-4f5d-cd23-9262cccb662e"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=3000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_sdg(texto_features,eta=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vnhGYFABBOQ"
      },
      "source": [
        "### Representacion 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "ZrrLNsOizTpa",
        "outputId": "ae0133b5-1580-4268-ea5b-d859abea6585"
      },
      "outputs": [],
      "source": [
        "# Bolsa de palabras\n",
        "vectorizer = CountVectorizer(max_features=3000, stop_words=stopwords.words('english'))\n",
        "\n",
        "# Construimos el vocabulario y tambien transformamos el texto\n",
        "texto_features = vectorizer.fit_transform(texto_procesado).toarray().astype(\"float16\")\n",
        "\n",
        "# Creamos el modelo y sus metricas\n",
        "create_model_sdg(texto_features,eta=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPObYKD7BDEO"
      },
      "source": [
        "## Recurrent Neural Network (LSTM - Long short-term memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6A-TEy1BEv1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTGOVeINE_K"
      },
      "outputs": [],
      "source": [
        "X = df_train['text'].values\n",
        "y = df_train['star_rating'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgGq37uyNRW6"
      },
      "outputs": [],
      "source": [
        "# Transformar las etiquetas categóricas en valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7J2yXrKBHcK"
      },
      "source": [
        "### Representacion 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0A3B3CFqa8V"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_sequence_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "DOU6dwoXqa-k",
        "outputId": "a352efdc-b4cc-4dd9-9d72-843bdc6462d1"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQsIvsf_qbA1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYEnPlvzqbDL"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXUd6R-TqqEG"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2wtQWDiqr2x"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOt1zX6Vqr5N"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuUoKdEsrFOl"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss en el conjunto de prueba: {loss}, Accuracy en el conjunto de prueba: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIoLU2_Cqvtc"
      },
      "outputs": [],
      "source": [
        "# Reporte de Clasificación\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "class_labels = label_encoder.classes_.astype(str)\n",
        "\n",
        "classification_rep = classification_report(y_test_labels, y_pred_labels, target_names=class_labels)\n",
        "\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvHJsz79qxRz"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Etiquetas verdaderas')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ETJsNDr6MX"
      },
      "source": [
        "### Representacion 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpTGUTbNr6Mh"
      },
      "outputs": [],
      "source": [
        "max_words = 20000\n",
        "max_sequence_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FreoHcN9r6Mi"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpelyTFMr6Mi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybIJkb44r6Mi"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(layers.Dense(80, activation='relu'))\n",
        "model.add(layers.Dense(45, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjcumx-Or6Mj"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_jmTs0Xr6Mj"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEnWNJIcr6Mj"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss en el conjunto de prueba: {loss}, Accuracy en el conjunto de prueba: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VcFColUr6Mj"
      },
      "outputs": [],
      "source": [
        "# Reporte de Clasificación\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "class_labels = label_encoder.classes_.astype(str)\n",
        "\n",
        "classification_rep = classification_report(y_test_labels, y_pred_labels, target_names=class_labels)\n",
        "\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55mssWGjr6Mk"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Etiquetas verdaderas')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYF8ib11r-Xm"
      },
      "source": [
        "### Representacion 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohJlay0yr-X2"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_sequence_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxt2m7Ipr-X2"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb-SQ6kmr-X3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkl9Itl5r-X3"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "# model.add(LSTM(128))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "# model.add(layers.Dropout(0.1))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d34z2zG8r-X4"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQZMfrCRr-X4"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 15\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wpjeDher-X5"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss en el conjunto de prueba: {loss}, Accuracy en el conjunto de prueba: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxaTwHxdr-X5"
      },
      "outputs": [],
      "source": [
        "# Reporte de Clasificación\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "class_labels = label_encoder.classes_.astype(str)\n",
        "\n",
        "classification_rep = classification_report(y_test_labels, y_pred_labels, target_names=class_labels)\n",
        "\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uoqwzh_r-X5"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Etiquetas verdaderas')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TxDu4x0GVRqE",
        "2IwbdFalVU_W",
        "cRQHt1gCr8Aj",
        "Dd_IP0obA9uR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
